{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49afb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f1edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837c29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collabmem.constants import LIC_DATA_PATH, LIC_EVAL_SUBSET_PATH, REPO_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee88acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_path = REPO_ROOT / \"examples\"\n",
    "if str(tgt_path) not in sys.path:\n",
    "    sys.path.append(str(tgt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febc293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 01:31:21,469 [INFO] collabllm: CollabLLM logging enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 01:31:23,101 [INFO] collabllm: Disable LiteLLM cache and logging by default. \n"
     ]
    }
   ],
   "source": [
    "from single_turn_ds import (\n",
    "    GSM8K,\n",
    "    BFCLSingleTurnDataset,\n",
    "    LiCCode,\n",
    "    SpiderDatabaseSingleTurn,\n",
    "    ToTToSingleTurn,\n",
    "    datasets_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c014f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LIC_DATA_PATH, \"r\") as f:\n",
    "    lic_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf3bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lic_dataset_names = [\n",
    "    \"gsm8k\",\n",
    "    \"lic-code\",\n",
    "    \"bfcl\",\n",
    "    \"spider\",\n",
    "    \"totto\",\n",
    "]\n",
    "lic_datasets = {k: datasets_info[k][\"class\"]() for k in lic_dataset_names}\n",
    "hf_datasets = {k: ds.to_hf_dataset() for k, ds in lic_datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c643d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
       "        num_rows: 60\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
       "        num_rows: 60\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_datasets[\"totto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0739e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stm = \"single_turn_metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f46d882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extraction_requirement': 'Return executable Python code only. Provide a valid function definition (def ...) that satisfies all test cases. Do not include explanations.',\n",
       " 'func_name': 'by_length',\n",
       " 'humaneval_raw_prompt': '\\ndef by_length(arr):\\n    \"\"\"\\n    Given an array of integers, sort the integers that are between 1 and 9 inclusive,\\n    reverse the resulting array, and then replace each digit by its corresponding name from\\n    \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\".\\n\\n    For example:\\n      arr = [2, 1, 1, 4, 5, 8, 2, 3]   \\n            -> sort arr -> [1, 1, 2, 2, 3, 4, 5, 8] \\n            -> reverse arr -> [8, 5, 4, 3, 2, 2, 1, 1]\\n      return [\"Eight\", \"Five\", \"Four\", \"Three\", \"Two\", \"Two\", \"One\", \"One\"]\\n    \\n      If the array is empty, return an empty array:\\n      arr = []\\n      return []\\n    \\n      If the array has any strange number ignore it:\\n      arr = [1, -1 , 55] \\n            -> sort arr -> [-1, 1, 55]\\n            -> reverse arr -> [55, 1, -1]\\n      return = [\\'One\\']\\n    \"\"\"\\n',\n",
       " 'source': 'humaneval',\n",
       " 'source_task_id': 'HumanEval/105',\n",
       " 'starter_code': None,\n",
       " 'system_prompt': 'You are an expert Python programmer. You will be given a question (problem specification) and will generate a correct Python program that matches the specification and passes all tests.\\n\\nFormat:\\n- [Standalone] Make sure that your answer consists of only one Python function at the top level. Do not wrap with a class or split into multiple functions.',\n",
       " 'task_id': 'sharded-HumanEval/105',\n",
       " 'testcases': '{\"inputs\": [\"[2, 1, 1, 4, 5, 8, 2, 3]\", \"[]\", \"[1, -1, 55]\", \"[1, -1, 3, 2]\", \"[9, 4, 8]\"], \"outputs\": [\"[\\\\\"Eight\\\\\", \\\\\"Five\\\\\", \\\\\"Four\\\\\", \\\\\"Three\\\\\", \\\\\"Two\\\\\", \\\\\"Two\\\\\", \\\\\"One\\\\\", \\\\\"One\\\\\"]\", \"[]\", \"[\\\\\"One\\\\\"]\", \"[\\\\\"Three\\\\\", \\\\\"Two\\\\\", \\\\\"One\\\\\"]\", \"[\\\\\"Nine\\\\\", \\\\\"Eight\\\\\", \\\\\"Four\\\\\"]\"], \"fn_name\": \"by_length\"}'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_datasets[\"lic-code\"][\"test\"][0][stm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ad79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lic_data_dict = {e[\"task_id\"]: e for e in lic_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee2e7c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling dataset: gsm8k\n",
      "handling dataset: lic-code\n",
      "handling dataset: bfcl\n",
      "handling dataset: spider\n",
      "handling dataset: totto\n",
      "Total eval examples collected: 268\n"
     ]
    }
   ],
   "source": [
    "lic_eval_data = []\n",
    "for ds_name, hf_ds in hf_datasets.items():\n",
    "    print(f\"handling dataset: {ds_name}\")\n",
    "    eval_split = hf_ds[\"eval\"] if \"eval\" in hf_ds.keys() else hf_ds[\"test\"]\n",
    "    for row in eval_split:\n",
    "        if ds_name == \"gsm8k\":\n",
    "            task_id = row[stm][\"source_task_id\"].upper()\n",
    "            task_id = f\"sharded-{task_id}\"\n",
    "        else:\n",
    "            task_id = row[stm][\"task_id\"]\n",
    "        lic_eval_data.append(lic_data_dict[task_id])\n",
    "print(f\"Total eval examples collected: {len(lic_eval_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da4d4d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train examples collected: 359\n"
     ]
    }
   ],
   "source": [
    "lic_train_data = []\n",
    "# everything in lic_data_dict that is not in lic_eval_data\n",
    "eval_task_ids = set(e[\"task_id\"] for e in lic_eval_data)\n",
    "for task_id, data in lic_data_dict.items():\n",
    "    if task_id not in eval_task_ids:\n",
    "        lic_train_data.append(data)\n",
    "print(f\"Total train examples collected: {len(lic_train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be2fcd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/v-homatthew/collabmem/src/lic/data/sharded_instructions_600.json\n"
     ]
    }
   ],
   "source": [
    "print(LIC_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33e2249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_split_path = LIC_DATA_PATH.parent / \"sharded_eval_subset.json\"\n",
    "assert eval_split_path == LIC_EVAL_SUBSET_PATH\n",
    "with open(eval_split_path, \"w\") as f:\n",
    "    json.dump(lic_eval_data, f, indent=2)\n",
    "\n",
    "train_split_path = LIC_DATA_PATH.parent / \"sharded_train_subset.json\"\n",
    "with open(train_split_path, \"w\") as f:\n",
    "    json.dump(lic_train_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36420bb",
   "metadata": {},
   "source": [
    "### make a mini subset for faster iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31c106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LIC_EVAL_SUBSET_PATH, \"r\") as f:\n",
    "    eval_subset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff719aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote mini eval subset to /home/v-homatthew/collabmem/src/lic/data/lic_mini_eval.json\n"
     ]
    }
   ],
   "source": [
    "mini_eval_path = LIC_DATA_PATH.parent / \"lic_mini_eval.json\"\n",
    "examples_per_task = 24\n",
    "mini_eval_subset = []\n",
    "for task in [\"math\", \"code\", \"actions\", \"database\", \"data2text\"]:\n",
    "    task_examples = [e for e in eval_subset if e[\"task\"] == task]\n",
    "    mini_eval_subset.extend(task_examples[:examples_per_task])\n",
    "with open(mini_eval_path, \"w\") as f:\n",
    "    json.dump(mini_eval_subset, f, indent=2)\n",
    "    print(f\"wrote mini eval subset to {mini_eval_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc60a0",
   "metadata": {},
   "source": [
    "## also make a mini train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa5d372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote mini train subset to /home/v-homatthew/collabmem/src/lic/data/lic_mini_train.json\n"
     ]
    }
   ],
   "source": [
    "# same principles, but I want 20 examples per task for training\n",
    "mini_train_path = LIC_DATA_PATH.parent / \"lic_mini_train.json\"\n",
    "examples_per_task = 20\n",
    "mini_train_subset = []\n",
    "train_task_ids = set(e[\"task_id\"] for e in lic_train_data)\n",
    "for task in [\"math\", \"code\", \"actions\", \"database\", \"data2text\"]:\n",
    "    task_examples = [e for e in lic_train_data if e[\"task\"] == task]\n",
    "    mini_train_subset.extend(task_examples[:examples_per_task])\n",
    "with open(mini_train_path, \"w\") as f:\n",
    "    json.dump(mini_train_subset, f, indent=2)\n",
    "    print(f\"wrote mini train subset to {mini_train_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colmem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
