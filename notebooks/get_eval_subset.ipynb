{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49afb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f1edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837c29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collabmem.constants import LIC_DATA_PATH, LIC_EVAL_SUBSET_PATH, REPO_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee88acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_path = REPO_ROOT / \"examples\"\n",
    "if str(tgt_path) not in sys.path:\n",
    "    sys.path.append(str(tgt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febc293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 05:13:43,867 [INFO] collabllm: CollabLLM logging enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 05:13:45,689 [INFO] collabllm: Disable LiteLLM cache and logging by default. \n"
     ]
    }
   ],
   "source": [
    "from single_turn_ds import (\n",
    "    GSM8K,\n",
    "    BFCLSingleTurnDataset,\n",
    "    LiCCode,\n",
    "    SpiderDatabaseSingleTurn,\n",
    "    ToTToSingleTurn,\n",
    "    datasets_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c014f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LIC_DATA_PATH, \"r\") as f:\n",
    "    lic_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf3bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lic_dataset_names = [\n",
    "    \"gsm8k\",\n",
    "    \"lic-code\",\n",
    "    \"bfcl\",\n",
    "    \"spider\",\n",
    "    \"totto\",\n",
    "]\n",
    "lic_datasets = {k: datasets_info[k][\"class\"]() for k in lic_dataset_names}\n",
    "hf_datasets = {k: ds.to_hf_dataset() for k, ds in lic_datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c643d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
       "        num_rows: 60\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
       "        num_rows: 60\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_datasets[\"totto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0739e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stm = \"single_turn_metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f46d882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extraction_requirement': 'Return executable Python code only. Provide a valid function definition (def ...) that satisfies all test cases. Do not include explanations.',\n",
       " 'func_name': 'by_length',\n",
       " 'humaneval_raw_prompt': '\\ndef by_length(arr):\\n    \"\"\"\\n    Given an array of integers, sort the integers that are between 1 and 9 inclusive,\\n    reverse the resulting array, and then replace each digit by its corresponding name from\\n    \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\".\\n\\n    For example:\\n      arr = [2, 1, 1, 4, 5, 8, 2, 3]   \\n            -> sort arr -> [1, 1, 2, 2, 3, 4, 5, 8] \\n            -> reverse arr -> [8, 5, 4, 3, 2, 2, 1, 1]\\n      return [\"Eight\", \"Five\", \"Four\", \"Three\", \"Two\", \"Two\", \"One\", \"One\"]\\n    \\n      If the array is empty, return an empty array:\\n      arr = []\\n      return []\\n    \\n      If the array has any strange number ignore it:\\n      arr = [1, -1 , 55] \\n            -> sort arr -> [-1, 1, 55]\\n            -> reverse arr -> [55, 1, -1]\\n      return = [\\'One\\']\\n    \"\"\"\\n',\n",
       " 'source': 'humaneval',\n",
       " 'source_task_id': 'HumanEval/105',\n",
       " 'starter_code': None,\n",
       " 'system_prompt': 'You are an expert Python programmer. You will be given a question (problem specification) and will generate a correct Python program that matches the specification and passes all tests.\\n\\nFormat:\\n- [Standalone] Make sure that your answer consists of only one Python function at the top level. Do not wrap with a class or split into multiple functions.',\n",
       " 'task_id': 'sharded-HumanEval/105',\n",
       " 'testcases': '{\"inputs\": [\"[2, 1, 1, 4, 5, 8, 2, 3]\", \"[]\", \"[1, -1, 55]\", \"[1, -1, 3, 2]\", \"[9, 4, 8]\"], \"outputs\": [\"[\\\\\"Eight\\\\\", \\\\\"Five\\\\\", \\\\\"Four\\\\\", \\\\\"Three\\\\\", \\\\\"Two\\\\\", \\\\\"Two\\\\\", \\\\\"One\\\\\", \\\\\"One\\\\\"]\", \"[]\", \"[\\\\\"One\\\\\"]\", \"[\\\\\"Three\\\\\", \\\\\"Two\\\\\", \\\\\"One\\\\\"]\", \"[\\\\\"Nine\\\\\", \\\\\"Eight\\\\\", \\\\\"Four\\\\\"]\"], \"fn_name\": \"by_length\"}'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_datasets[\"lic-code\"][\"test\"][0][stm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ad79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lic_data_dict = {e[\"task_id\"]: e for e in lic_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee2e7c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling dataset: gsm8k\n",
      "handling dataset: lic-code\n",
      "handling dataset: bfcl\n",
      "handling dataset: spider\n",
      "handling dataset: totto\n",
      "Total eval examples collected: 268\n"
     ]
    }
   ],
   "source": [
    "lic_eval_data = []\n",
    "for ds_name, hf_ds in hf_datasets.items():\n",
    "    print(f\"handling dataset: {ds_name}\")\n",
    "    eval_split = hf_ds[\"eval\"] if \"eval\" in hf_ds.keys() else hf_ds[\"test\"]\n",
    "    for row in eval_split:\n",
    "        if ds_name == \"gsm8k\":\n",
    "            task_id = row[stm][\"source_task_id\"].upper()\n",
    "            task_id = f\"sharded-{task_id}\"\n",
    "        else:\n",
    "            task_id = row[stm][\"task_id\"]\n",
    "        lic_eval_data.append(lic_data_dict[task_id])\n",
    "print(f\"Total eval examples collected: {len(lic_eval_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da4d4d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train examples collected: 359\n"
     ]
    }
   ],
   "source": [
    "lic_train_data = []\n",
    "# everything in lic_data_dict that is not in lic_eval_data\n",
    "eval_task_ids = set(e[\"task_id\"] for e in lic_eval_data)\n",
    "for task_id, data in lic_data_dict.items():\n",
    "    if task_id not in eval_task_ids:\n",
    "        lic_train_data.append(data)\n",
    "print(f\"Total train examples collected: {len(lic_train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be2fcd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/v-homatthew/collabmem/src/lic/data/sharded_instructions_600.json\n"
     ]
    }
   ],
   "source": [
    "print(LIC_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33e2249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_split_path = LIC_DATA_PATH.parent / \"sharded_eval_subset.json\"\n",
    "assert eval_split_path == LIC_EVAL_SUBSET_PATH\n",
    "with open(eval_split_path, \"w\") as f:\n",
    "    json.dump(lic_eval_data, f, indent=2)\n",
    "\n",
    "train_split_path = LIC_DATA_PATH.parent / \"sharded_train_subset.json\"\n",
    "with open(train_split_path, \"w\") as f:\n",
    "    json.dump(lic_train_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36420bb",
   "metadata": {},
   "source": [
    "### make a mini subset for faster iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31c106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LIC_EVAL_SUBSET_PATH, \"r\") as f:\n",
    "    eval_subset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff719aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote mini eval subset to /home/v-homatthew/collabmem/src/lic/data/lic_mini_eval.json\n"
     ]
    }
   ],
   "source": [
    "mini_eval_path = LIC_DATA_PATH.parent / \"lic_mini_eval.json\"\n",
    "examples_per_task = 24\n",
    "mini_eval_subset = []\n",
    "for task in [\"math\", \"code\", \"actions\", \"database\", \"data2text\"]:\n",
    "    task_examples = [e for e in eval_subset if e[\"task\"] == task]\n",
    "    mini_eval_subset.extend(task_examples[:examples_per_task])\n",
    "with open(mini_eval_path, \"w\") as f:\n",
    "    json.dump(mini_eval_subset, f, indent=2)\n",
    "    print(f\"wrote mini eval subset to {mini_eval_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7f18073",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_eval_path = LIC_DATA_PATH.parent / \"lic_mini_eval.json\"\n",
    "with open(mini_eval_path, \"r\") as f:\n",
    "    mini_eval_subset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccefa2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '90 single use contacts come in 1 box and will last Pete 45 days.  Each box is $100.00 and currently 10% off.  If he buys 2 boxes of contact, how much will each pair of contacts cost?', 'answer': \"Each box of contacts is $100.00 with 10% off so that's 100*.10 = $<<100*.10=10.00>>10.00 off\\nSo the box was $100.00 and he has $10.00 off so each box will cost 100-10 = $<<100-10=90.00>>90.00\\nHe buys 2 boxes and each box costs $90.00 so that's 2*90= $<<2*90=180.00>>180.00\\n1 box of contacts has 90 contacts and he buys 2 boxes so that's 90*2 = <<90*2=180>>180 contacts\\nHe needs 1 contact for each eye and he has 180 contacts so that's 180/2 = <<180/2=90>>90 pairs of contacts\\nHe spent $180.00 to have 90 pairs of contacts so each pair of contacts costs 180/90 = $<<180/90=2.00>>2.00 a pair\\n#### 2\", 'task_id': 'sharded-GSM8K/584', 'shards': [{'shard_id': 1, 'shard': \"what's the cost per pair of contacts after Pete's purchase?\"}, {'shard_id': 2, 'shard': 'each box contains 90 single-use contact lenses'}, {'shard_id': 3, 'shard': '1 box lasts Pete 45 days'}, {'shard_id': 4, 'shard': 'each box costs $100'}, {'shard_id': 5, 'shard': \"right now, there's a 10% discount on the boxes of contacts\"}, {'shard_id': 6, 'shard': 'Pete is purchasing 2 boxes of contacts in total'}], 'task': 'math', 'full_spec_q': '90 single use contacts come in 1 box and will last Pete 45 days.  Each box is $100.00 and currently 10% off.  If he buys 2 boxes of contact, how much will each pair of contacts cost?', 'ground_truth_a': \"Each box of contacts is $100.00 with 10% off so that's 100*.10 = $<<100*.10=10.00>>10.00 off\\nSo the box was $100.00 and he has $10.00 off so each box will cost 100-10 = $<<100-10=90.00>>90.00\\nHe buys 2 boxes and each box costs $90.00 so that's 2*90= $<<2*90=180.00>>180.00\\n1 box of contacts has 90 contacts and he buys 2 boxes so that's 90*2 = <<90*2=180>>180 contacts\\nHe needs 1 contact for each eye and he has 180 contacts so that's 180/2 = <<180/2=90>>90 pairs of contacts\\nHe spent $180.00 to have 90 pairs of contacts so each pair of contacts costs 180/90 = $<<180/90=2.00>>2.00 a pair\\n#### 2\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'answer', 'task_id', 'shards', 'task', 'full_spec_q', 'ground_truth_a'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first math task from mini_eval_subset\n",
    "for e in mini_eval_subset:\n",
    "    if e[\"task\"] == \"math\":\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "e.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f511d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a824d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mini train with HumanEval examples collected: 22\n",
      "Task counts in mini train with HumanEval subset:\n",
      "code: 22\n",
      "wrote mini train with HumanEval subset to /home/v-homatthew/collabmem/src/lic/data/lic_mini_train_with_humaneval.json\n"
     ]
    }
   ],
   "source": [
    "# I want yet another split\n",
    "# from from the train split guaranteeing that it's disjoint from the \"mini eval split\"\n",
    "# filter code samples such that task_id always contains HumanEval (not livecodebench)\n",
    "\n",
    "mini_train_with_humaneval = []\n",
    "mini_eval_task_ids = set(e[\"task_id\"] for e in mini_eval_subset)\n",
    "\n",
    "per_task = 30\n",
    "\n",
    "for e in lic_train_data:\n",
    "    if e[\"task_id\"] in mini_eval_task_ids:\n",
    "        continue\n",
    "    if e[\"task\"] == \"code\" and \"HumanEval\" in e[\"task_id\"]:\n",
    "        mini_train_with_humaneval.append(e)\n",
    "        if len(mini_train_with_humaneval) >= per_task:\n",
    "            break\n",
    "print(f\"Total mini train with HumanEval examples collected: {len(mini_train_with_humaneval)}\")\n",
    "# print per task counts\n",
    "task_counts = Counter(e[\"task\"] for e in mini_train_with_humaneval)\n",
    "print(\"Task counts in mini train with HumanEval subset:\")\n",
    "for task, count in task_counts.items():\n",
    "    print(f\"{task}: {count}\")\n",
    "mini_train_path = LIC_DATA_PATH.parent / \"lic_mini_train_with_humaneval.json\"\n",
    "with open(mini_train_path, \"w\") as f:\n",
    "    json.dump(mini_train_with_humaneval, f, indent=2)\n",
    "    print(f\"wrote mini train with HumanEval subset to {mini_train_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc60a0",
   "metadata": {},
   "source": [
    "## also make a mini train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa5d372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote mini train subset to /home/v-homatthew/collabmem/src/lic/data/lic_mini_train.json\n"
     ]
    }
   ],
   "source": [
    "# same principles, but I want 20 examples per task for training\n",
    "mini_train_path = LIC_DATA_PATH.parent / \"lic_mini_train.json\"\n",
    "examples_per_task = 20\n",
    "mini_train_subset = []\n",
    "train_task_ids = set(e[\"task_id\"] for e in lic_train_data)\n",
    "for task in [\"math\", \"code\", \"actions\", \"database\", \"data2text\"]:\n",
    "    task_examples = [e for e in lic_train_data if e[\"task\"] == task]\n",
    "    mini_train_subset.extend(task_examples[:examples_per_task])\n",
    "with open(mini_train_path, \"w\") as f:\n",
    "    json.dump(mini_train_subset, f, indent=2)\n",
    "    print(f\"wrote mini train subset to {mini_train_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colmem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
